{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26299f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d167982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b2a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b36198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec3212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie_reviews', 'movie_reviews.zip', 'stopwords', 'stopwords.zip', 'wordnet.zip', 'words', 'words.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find('corpora')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a73088",
   "metadata": {},
   "source": [
    "#### Tokenization: Breaking down text into words (tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8286a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35fe64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hi... today we will learn about tokenization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b9045b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi... today we will learn about tokenization'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0635c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae266268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', '...', 'today', 'we', 'will', 'learn', 'about', 'tokenization']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8ce95",
   "metadata": {},
   "source": [
    "##### Is tokenization splitting the text based on 'spaces' in the string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc84d58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi...', 'today', 'we', 'will', 'learn', 'about', 'tokenization']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eabc032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e52e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a54aedac",
   "metadata": {},
   "source": [
    "#### Part-of-Speech Tagging (Noun, Verb, Adverb, Adjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0dec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2677b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "572e1fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi', 'NN'), ('...', ':'), ('today', 'NN'), ('we', 'PRP'), ('will', 'MD'), ('learn', 'VB'), ('about', 'IN'), ('tokenization', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5949e",
   "metadata": {},
   "source": [
    "#### Stemming and Lemmatization: Reducing words to their base/root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d44654b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9d8d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc44cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ea65b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', '...', 'today', 'we', 'will', 'learn', 'about', 'token']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5656b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4b61dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e69671a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', '...', 'today', 'we', 'will', 'learn', 'about', 'tokenization']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1eee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d1a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e35b7808",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition (NER): Identifying proper nouns in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e35b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58aef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Apple is looking at buying U.K. startup for $1 billion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098354e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0bf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3b0d0d6",
   "metadata": {},
   "source": [
    "#### Stopwords: Common words that are often filtered out in text processing.\n",
    "\n",
    "* Usage: Removing noise from text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7de85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06b354ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a02d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd408a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = [w for w in tokens if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e14d633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', '...', 'today', 'we', 'will', 'learn', 'about', 'tokenization']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c491c2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', '...', 'today', 'learn', 'tokenization']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bdf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f9bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67279f60",
   "metadata": {},
   "source": [
    "#### Frequency Distributions: Counting word frequencies.\n",
    "\n",
    "* Usage: Analyzing word frequency patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d698e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb09b5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', '...', 'today', 'we', 'will', 'learn', 'about', 'tokenization']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13301821",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ff19983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi', 1), ('...', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(fdist.most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f98a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afce430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3126b9e",
   "metadata": {},
   "source": [
    "#### n-grams: Generating combinations of N words in a row.\n",
    "\n",
    "* Usage: Used in text predictions, text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d2d3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fde9ec42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', '...', 'today', 'we', 'will', 'learn', 'about', 'tokenization']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0669139",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = list(ngrams(tokens, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "082b4b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi', '...'), ('...', 'today'), ('today', 'we'), ('we', 'will'), ('will', 'learn'), ('learn', 'about'), ('about', 'tokenization')]\n"
     ]
    }
   ],
   "source": [
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79de9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = list(ngrams(tokens,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dd4548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi', '...', 'today'), ('...', 'today', 'we'), ('today', 'we', 'will'), ('we', 'will', 'learn'), ('will', 'learn', 'about'), ('learn', 'about', 'tokenization')]\n"
     ]
    }
   ],
   "source": [
    "print(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dcf638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
